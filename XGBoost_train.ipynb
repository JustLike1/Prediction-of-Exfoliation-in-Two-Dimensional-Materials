{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 分类模型 - 优化版本\n",
    "# 保存每个fold的详细结果，包括准确率、混淆矩阵、F1等指标\n",
    "# 最终绘制混淆矩阵、ROC曲线和SHAP分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 加载CSV数据\n",
    "def load_data_from_csv(csv_path):\n",
    "    \"\"\"从CSV文件加载数据\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loaded data from: {csv_path}\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    \n",
    "    # 去除filename列\n",
    "    if 'filename' in df.columns:\n",
    "        df = df.drop('filename', axis=1)\n",
    "    \n",
    "    # 分离特征和标签\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(\"'label' column not found in CSV file\")\n",
    "    \n",
    "    y = df['label'].values\n",
    "    X = df.drop('label', axis=1).values\n",
    "    feature_names = df.drop('label', axis=1).columns.tolist()\n",
    "    \n",
    "    print(f\"Features: {len(feature_names)}\")\n",
    "    print(f\"Positive samples: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.2f}%)\")\n",
    "    print(f\"Negative samples: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.2f}%)\")\n",
    "    \n",
    "    return X, y, feature_names\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost模型训练和预测函数\n",
    "def train_xgboost_optimized(X_train, y_train, X_val=None, y_val=None, seed=51):\n",
    "    \"\"\"使用优化后的参数训练XGBoost模型，并记录学习曲线\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 9,\n",
    "        'learning_rate': 0.042,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'scale_pos_weight': 2.23,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0.2,\n",
    "        'seed': seed\n",
    "    }\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    # 如果提供了验证集，记录学习曲线\n",
    "    if X_val is not None and y_val is not None:\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "        evals_result = {}\n",
    "        model = xgb.train(params, dtrain, num_boost_round=100, \n",
    "                         evals=evals, evals_result=evals_result, \n",
    "                         verbose_eval=False)\n",
    "        return model, evals_result\n",
    "    else:\n",
    "        model = xgb.train(params, dtrain, num_boost_round=100, verbose_eval=False)\n",
    "        return model, None\n",
    "\n",
    "def predict_xgboost(model, X_test):\n",
    "    \"\"\"XGBoost预测\"\"\"\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_pred_proba = model.predict(dtest)\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "csv_path = 'data/dataset/features_final_38_new.csv'\n",
    "X, y, feature_names = load_data_from_csv(csv_path)\n",
    "\n",
    "# 设置参数\n",
    "SPLIT_SEED = 43\n",
    "XGBOOST_MODEL_SEED = 51\n",
    "N_SPLITS = 5\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"XGBoost 交叉验证配置\")\n",
    "print(f\"数据集: {csv_path}\")\n",
    "print(f\"特征数量: {len(feature_names)}\")\n",
    "print(f\"数据集划分 Seed: {SPLIT_SEED}\")\n",
    "print(f\"XGBoost 模型 Seed: {XGBOOST_MODEL_SEED}\")\n",
    "print(f\"Fold数量: {N_SPLITS}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证并保存详细结果\n",
    "kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SPLIT_SEED)\n",
    "\n",
    "# 存储所有结果\n",
    "fold_results = []\n",
    "all_models = []\n",
    "all_X_train = []\n",
    "all_y_train = []\n",
    "all_X_test = []\n",
    "all_y_test = []\n",
    "all_learning_curves = []  # 存储学习曲线\n",
    "\n",
    "print(\"开始交叉验证...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"\\nFold {fold+1}/{N_SPLITS}\")\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # 保存数据用于SHAP分析\n",
    "    all_X_train.append(X_train)\n",
    "    all_y_train.append(y_train)\n",
    "    all_X_test.append(X_test)\n",
    "    all_y_test.append(y_test)\n",
    "    \n",
    "    # 训练模型并获取学习曲线（使用测试集作为验证集记录学习曲线，不影响训练数据量）\n",
    "    model, evals_result = train_xgboost_optimized(X_train, y_train, X_test, y_test, XGBOOST_MODEL_SEED)\n",
    "    all_models.append(model)\n",
    "    all_learning_curves.append(evals_result)  # 保存学习曲线\n",
    "    \n",
    "    # 预测\n",
    "    y_pred, y_pred_proba = predict_xgboost(model, X_test)\n",
    "    \n",
    "    # 计算各种指标\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # 分类指标\n",
    "    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
    "    \n",
    "    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
    "    \n",
    "    # 计算ROC曲线数据\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    # 存储结果\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': float(accuracy),\n",
    "        'auc': float(auc_score),\n",
    "        'confusion_matrix': {\n",
    "            'tn': int(tn), 'fp': int(fp), 'fn': int(fn), 'tp': int(tp)\n",
    "        },\n",
    "        'class_0': {\n",
    "            'precision': float(precision_0),\n",
    "            'recall': float(recall_0),\n",
    "            'f1': float(f1_0)\n",
    "        },\n",
    "        'class_1': {\n",
    "            'precision': float(precision_1),\n",
    "            'recall': float(recall_1),\n",
    "            'f1': float(f1_1)\n",
    "        },\n",
    "        'roc_curve': {\n",
    "            'fpr': fpr.tolist(),\n",
    "            'tpr': tpr.tolist(),\n",
    "            'thresholds': thresholds.tolist()\n",
    "        }\n",
    "    }\n",
    "    fold_results.append(fold_result)\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  AUC: {auc_score:.4f}\")\n",
    "    print(f\"  Class 0 - Precision: {precision_0:.4f}, Recall: {recall_0:.4f}, F1: {f1_0:.4f}\")\n",
    "    print(f\"  Class 1 - Precision: {precision_1:.4f}, Recall: {recall_1:.4f}, F1: {f1_1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"交叉验证完成\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算平均指标\n",
    "avg_metrics = {\n",
    "    'accuracy': np.mean([f['accuracy'] for f in fold_results]),\n",
    "    'accuracy_std': np.std([f['accuracy'] for f in fold_results]),\n",
    "    'auc': np.mean([f['auc'] for f in fold_results]),\n",
    "    'auc_std': np.std([f['auc'] for f in fold_results]),\n",
    "    'class_0': {\n",
    "        'precision': np.mean([f['class_0']['precision'] for f in fold_results]),\n",
    "        'recall': np.mean([f['class_0']['recall'] for f in fold_results]),\n",
    "        'f1': np.mean([f['class_0']['f1'] for f in fold_results])\n",
    "    },\n",
    "    'class_1': {\n",
    "        'precision': np.mean([f['class_1']['precision'] for f in fold_results]),\n",
    "        'recall': np.mean([f['class_1']['recall'] for f in fold_results]),\n",
    "        'f1': np.mean([f['class_1']['f1'] for f in fold_results])\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"平均指标:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Accuracy: {avg_metrics['accuracy']:.4f} ± {avg_metrics['accuracy_std']:.4f}\")\n",
    "print(f\"AUC: {avg_metrics['auc']:.4f} ± {avg_metrics['auc_std']:.4f}\")\n",
    "print(f\"\\nClass 0 (Negative):\")\n",
    "print(f\"  Precision: {avg_metrics['class_0']['precision']:.4f}\")\n",
    "print(f\"  Recall: {avg_metrics['class_0']['recall']:.4f}\")\n",
    "print(f\"  F1: {avg_metrics['class_0']['f1']:.4f}\")\n",
    "print(f\"\\nClass 1 (Positive):\")\n",
    "print(f\"  Precision: {avg_metrics['class_1']['precision']:.4f}\")\n",
    "print(f\"  Recall: {avg_metrics['class_1']['recall']:.4f}\")\n",
    "print(f\"  F1: {avg_metrics['class_1']['f1']:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算特征重要性\n",
    "print(\"计算特征重要性...\")\n",
    "\n",
    "fold_feature_importances = []\n",
    "for fold_idx, model in enumerate(all_models):\n",
    "    importance_dict = model.get_score(importance_type='gain')\n",
    "    fold_importance = {}\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        key = f'f{i}'\n",
    "        fold_importance[fname] = float(importance_dict.get(key, 0))\n",
    "    fold_feature_importances.append(fold_importance)\n",
    "\n",
    "# 计算平均特征重要性\n",
    "avg_feature_importance = {}\n",
    "for fname in feature_names:\n",
    "    importances = [fold_imp[fname] for fold_imp in fold_feature_importances]\n",
    "    avg_feature_importance[fname] = float(np.mean(importances))\n",
    "\n",
    "# 排序并获取Top 10\n",
    "sorted_features = sorted(avg_feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "top_10_features = sorted_features[:10]\n",
    "\n",
    "print(\"\\nTop 10 最重要的特征:\")\n",
    "print(\"-\" * 70)\n",
    "for i, (feat, imp) in enumerate(top_10_features, 1):\n",
    "    print(f\"{i:2d}. {feat:<40} {imp:.2f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果到文件\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = f'training_results/run_xgboost_{timestamp}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 保存fold结果\n",
    "results_data = {\n",
    "    'timestamp': timestamp,\n",
    "    'dataset': csv_path,\n",
    "    'n_features': len(feature_names),\n",
    "    'feature_names': feature_names,\n",
    "    'config': {\n",
    "        'split_seed': SPLIT_SEED,\n",
    "        'model_seed': XGBOOST_MODEL_SEED,\n",
    "        'n_splits': N_SPLITS,\n",
    "    },\n",
    "    'fold_results': fold_results,\n",
    "    'average_metrics': {k: float(v) if not isinstance(v, dict) else v for k, v in avg_metrics.items()},\n",
    "    'feature_importance': avg_feature_importance,\n",
    "    'top_10_features': {feat: float(imp) for feat, imp in top_10_features}\n",
    "}\n",
    "\n",
    "# 保存完整结果\n",
    "with open(f'{save_dir}/complete_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 保存平均指标（单独文件）\n",
    "with open(f'{save_dir}/average_metrics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(avg_metrics, f, indent=4)\n",
    "\n",
    "# 保存特征重要性\n",
    "with open(f'{save_dir}/feature_importance.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(avg_feature_importance, f, indent=4)\n",
    "\n",
    "print(f\"结果已保存到: {save_dir}\")\n",
    "print(f\"  - complete_results.json: 完整结果\")\n",
    "print(f\"  - average_metrics.json: 平均指标\")\n",
    "print(f\"  - feature_importance.json: 特征重要性\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存学习曲线数据到CSV\n",
    "print(\"保存学习曲线数据到CSV...\")\n",
    "\n",
    "for fold_idx, evals_result in enumerate(all_learning_curves):\n",
    "    # 创建DataFrame\n",
    "    learning_curve_df = pd.DataFrame({\n",
    "        'iteration': range(1, len(evals_result['train']['logloss']) + 1),\n",
    "        'train_logloss': evals_result['train']['logloss'],\n",
    "        'val_logloss': evals_result['val']['logloss']\n",
    "    })\n",
    "    \n",
    "    # 保存到CSV\n",
    "    csv_filename = f'{save_dir}/learning_curve_fold_{fold_idx+1}.csv'\n",
    "    learning_curve_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"  - Fold {fold_idx+1} 学习曲线已保存: {csv_filename}\")\n",
    "\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ROC曲线数据到CSV\n",
    "print(\"保存ROC曲线数据到CSV...\")\n",
    "\n",
    "for fold_idx, fold_result in enumerate(fold_results):\n",
    "    # 创建DataFrame\n",
    "    roc_df = pd.DataFrame({\n",
    "        'fpr': fold_result['roc_curve']['fpr'],\n",
    "        'tpr': fold_result['roc_curve']['tpr'],\n",
    "        'thresholds': fold_result['roc_curve']['thresholds']\n",
    "    })\n",
    "    \n",
    "    # 保存到CSV\n",
    "    csv_filename = f'{save_dir}/roc_curve_fold_{fold_idx+1}.csv'\n",
    "    roc_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"  - Fold {fold_idx+1} ROC曲线已保存: {csv_filename}\")\n",
    "\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存平均学习曲线数据到CSV（包含std区域）\n",
    "print(\"保存平均学习曲线数据到CSV...\")\n",
    "\n",
    "# 计算平均值和标准差\n",
    "train_logloss_all = np.array([evals_result['train']['logloss'] for evals_result in all_learning_curves])\n",
    "val_logloss_all = np.array([evals_result['val']['logloss'] for evals_result in all_learning_curves])\n",
    "\n",
    "mean_train_logloss = np.mean(train_logloss_all, axis=0)\n",
    "mean_val_logloss = np.mean(val_logloss_all, axis=0)\n",
    "std_train_logloss = np.std(train_logloss_all, axis=0)\n",
    "std_val_logloss = np.std(val_logloss_all, axis=0)\n",
    "\n",
    "# 创建DataFrame\n",
    "mean_learning_curve_df = pd.DataFrame({\n",
    "    'iteration': range(1, len(mean_train_logloss) + 1),\n",
    "    'mean_train_logloss': mean_train_logloss,\n",
    "    'mean_val_logloss': mean_val_logloss,\n",
    "    'std_train_logloss': std_train_logloss,\n",
    "    'std_val_logloss': std_val_logloss,\n",
    "    'train_upper': mean_train_logloss + std_train_logloss,\n",
    "    'train_lower': mean_train_logloss - std_train_logloss,\n",
    "    'val_upper': mean_val_logloss + std_val_logloss,\n",
    "    'val_lower': mean_val_logloss - std_val_logloss\n",
    "})\n",
    "\n",
    "# 保存到CSV\n",
    "csv_filename = f'{save_dir}/mean_learning_curve.csv'\n",
    "mean_learning_curve_df.to_csv(csv_filename, index=False)\n",
    "print(f\"  - 平均学习曲线已保存: {csv_filename}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存平均ROC曲线数据到CSV（包含std区域）\n",
    "print(\"保存平均ROC曲线数据到CSV...\")\n",
    "\n",
    "# 计算平均ROC曲线（插值到统一的fpr点）\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for fold_result in fold_results:\n",
    "    fpr = np.array(fold_result['roc_curve']['fpr'])\n",
    "    tpr = np.array(fold_result['roc_curve']['tpr'])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "# 计算平均AUC和std\n",
    "mean_auc_value = auc(mean_fpr, mean_tpr)\n",
    "std_auc_value = np.std([f['auc'] for f in fold_results])\n",
    "\n",
    "# 创建DataFrame\n",
    "mean_roc_df = pd.DataFrame({\n",
    "    'fpr': mean_fpr,\n",
    "    'mean_tpr': mean_tpr,\n",
    "    'std_tpr': std_tpr,\n",
    "    'tpr_upper': tpr_upper,\n",
    "    'tpr_lower': tpr_lower\n",
    "})\n",
    "\n",
    "# 保存到CSV\n",
    "csv_filename = f'{save_dir}/mean_roc_curve.csv'\n",
    "mean_roc_df.to_csv(csv_filename, index=False)\n",
    "print(f\"  - 平均ROC曲线已保存: {csv_filename}\")\n",
    "print(f\"  - Mean AUC: {mean_auc_value:.4f} ± {std_auc_value:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制学习曲线 (Log Loss)\n",
    "print(\"绘制学习曲线...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for fold_idx, evals_result in enumerate(all_learning_curves):\n",
    "    ax = axes[fold_idx]\n",
    "    \n",
    "    iterations = range(1, len(evals_result['train']['logloss']) + 1)\n",
    "    train_logloss = evals_result['train']['logloss']\n",
    "    val_logloss = evals_result['val']['logloss']\n",
    "    \n",
    "    ax.plot(iterations, train_logloss, label='Train', color='#1f77b4', linewidth=2)\n",
    "    ax.plot(iterations, val_logloss, label='Validation', color='#ff7f0e', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Iteration', fontsize=11)\n",
    "    ax.set_ylabel('Log Loss', fontsize=11)\n",
    "    ax.set_title(f'Fold {fold_idx+1} - Learning Curve', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 计算并绘制平均学习曲线\n",
    "ax = axes[5]\n",
    "\n",
    "# 获取所有fold的学习曲线长度\n",
    "max_iterations = max(len(evals_result['train']['logloss']) for evals_result in all_learning_curves)\n",
    "iterations = range(1, max_iterations + 1)\n",
    "\n",
    "# 计算平均值\n",
    "train_logloss_all = np.array([evals_result['train']['logloss'] for evals_result in all_learning_curves])\n",
    "val_logloss_all = np.array([evals_result['val']['logloss'] for evals_result in all_learning_curves])\n",
    "\n",
    "mean_train_logloss = np.mean(train_logloss_all, axis=0)\n",
    "mean_val_logloss = np.mean(val_logloss_all, axis=0)\n",
    "std_train_logloss = np.std(train_logloss_all, axis=0)\n",
    "std_val_logloss = np.std(val_logloss_all, axis=0)\n",
    "\n",
    "ax.plot(iterations, mean_train_logloss, label='Mean Train', color='#1f77b4', linewidth=3)\n",
    "ax.plot(iterations, mean_val_logloss, label='Mean Validation', color='#ff7f0e', linewidth=3)\n",
    "\n",
    "# 添加标准差区域\n",
    "ax.fill_between(iterations, \n",
    "                mean_train_logloss - std_train_logloss,\n",
    "                mean_train_logloss + std_train_logloss,\n",
    "                alpha=0.2, color='#1f77b4', label='Train ± 1 std')\n",
    "ax.fill_between(iterations,\n",
    "                mean_val_logloss - std_val_logloss,\n",
    "                mean_val_logloss + std_val_logloss,\n",
    "                alpha=0.2, color='#ff7f0e', label='Val ± 1 std')\n",
    "\n",
    "ax.set_xlabel('Iteration', fontsize=11)\n",
    "ax.set_ylabel('Log Loss', fontsize=11)\n",
    "ax.set_title('Average Learning Curve', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"学习曲线已保存: {save_dir}/learning_curves.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "print(\"绘制混淆矩阵...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for fold_idx, fold_result in enumerate(fold_results):\n",
    "    cm_data = fold_result['confusion_matrix']\n",
    "    cm = np.array([[cm_data['tn'], cm_data['fp']], \n",
    "                   [cm_data['fn'], cm_data['tp']]])\n",
    "    \n",
    "    ax = axes[fold_idx]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "                cbar_kws={'label': 'Count'}, annot_kws={'fontsize': 12})\n",
    "    ax.set_xlabel('Predicted Label', fontsize=11)\n",
    "    ax.set_ylabel('True Label', fontsize=11)\n",
    "    ax.set_title(f\"Fold {fold_idx+1} - Acc: {fold_result['accuracy']:.4f}\", \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_xticklabels(['Negative', 'Positive'])\n",
    "    ax.set_yticklabels(['Negative', 'Positive'])\n",
    "\n",
    "# 计算并绘制平均混淆矩阵\n",
    "avg_cm = np.zeros((2, 2))\n",
    "for fold_result in fold_results:\n",
    "    cm_data = fold_result['confusion_matrix']\n",
    "    avg_cm += np.array([[cm_data['tn'], cm_data['fp']], \n",
    "                        [cm_data['fn'], cm_data['tp']]])\n",
    "avg_cm = avg_cm / N_SPLITS\n",
    "\n",
    "ax = axes[5]\n",
    "sns.heatmap(avg_cm, annot=True, fmt='.1f', cmap='Greens', ax=ax, \n",
    "            cbar_kws={'label': 'Average Count'}, annot_kws={'fontsize': 12})\n",
    "ax.set_xlabel('Predicted Label', fontsize=11)\n",
    "ax.set_ylabel('True Label', fontsize=11)\n",
    "ax.set_title(f\"Average - Acc: {avg_metrics['accuracy']:.4f}\", \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.set_xticklabels(['Negative', 'Positive'])\n",
    "ax.set_yticklabels(['Negative', 'Positive'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"混淆矩阵已保存: {save_dir}/confusion_matrices.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制ROC曲线\n",
    "print(\"绘制ROC曲线...\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# 绘制每个fold的ROC曲线\n",
    "for fold_idx, fold_result in enumerate(fold_results):\n",
    "    fpr = np.array(fold_result['roc_curve']['fpr'])\n",
    "    tpr = np.array(fold_result['roc_curve']['tpr'])\n",
    "    roc_auc = fold_result['auc']\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=colors[fold_idx], lw=2, alpha=0.8,\n",
    "             label=f\"Fold {fold_idx+1} (AUC = {roc_auc:.4f})\")\n",
    "\n",
    "# 绘制平均ROC曲线（插值）\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for fold_result in fold_results:\n",
    "    fpr = np.array(fold_result['roc_curve']['fpr'])\n",
    "    tpr = np.array(fold_result['roc_curve']['tpr'])\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std([f['auc'] for f in fold_results])\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='navy', lw=3, linestyle='--',\n",
    "         label=f'Mean ROC (AUC = {mean_auc:.4f} ± {std_auc:.4f})')\n",
    "\n",
    "# 绘制标准差区域\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.2,\n",
    "                 label='± 1 std. dev.')\n",
    "\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.5)')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.title('ROC Curves - XGBoost Cross Validation', fontsize=15, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(f'{save_dir}/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC曲线已保存: {save_dir}/roc_curves.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP分析 - 使用最后一个fold的模型和数据\n",
    "print(\"进行SHAP分析...\")\n",
    "print(\"注意: SHAP分析可能需要较长时间...\")\n",
    "\n",
    "# 使用最后一个fold的模型进行SHAP分析\n",
    "model = all_models[-1]\n",
    "X_train_shap = all_X_train[-1]\n",
    "X_test_shap = all_X_test[-1]\n",
    "\n",
    "# 创建SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# 计算SHAP值（使用测试集）\n",
    "shap_values = explainer.shap_values(X_test_shap)\n",
    "\n",
    "print(\"SHAP分析完成\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制SHAP Summary Plot - Top 10特征\n",
    "print(\"绘制SHAP Summary Plot (Top 10 特征)...\")\n",
    "\n",
    "# 获取Top 10特征的索引\n",
    "top_10_feature_names = [feat for feat, _ in top_10_features]\n",
    "top_10_indices = [feature_names.index(fname) for fname in top_10_feature_names]\n",
    "\n",
    "# 提取Top 10特征的SHAP值\n",
    "shap_values_top10 = shap_values[:, top_10_indices]\n",
    "X_test_top10 = X_test_shap[:, top_10_indices]\n",
    "\n",
    "# 创建DataFrame便于显示\n",
    "X_test_top10_df = pd.DataFrame(X_test_top10, columns=top_10_feature_names)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_top10, X_test_top10_df, \n",
    "                  plot_type=\"dot\", show=False, \n",
    "                  max_display=10)\n",
    "plt.title('SHAP Summary Plot - Top 10 Features', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/shap_summary_top10.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"SHAP Summary Plot已保存: {save_dir}/shap_summary_top10.png\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"所有分析完成！\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n结果保存位置: {save_dir}\")\n",
    "print(\"包含文件:\")\n",
    "print(\"  1. complete_results.json - 完整的训练结果\")\n",
    "print(\"  2. average_metrics.json - 平均指标\")\n",
    "print(\"  3. feature_importance.json - 特征重要性\")\n",
    "print(\"  4. confusion_matrices.png - 混淆矩阵可视化\")\n",
    "print(\"  5. roc_curves.png - ROC曲线\")\n",
    "print(\"  6. shap_summary_top10.png - SHAP分析（Top 10特征）\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
