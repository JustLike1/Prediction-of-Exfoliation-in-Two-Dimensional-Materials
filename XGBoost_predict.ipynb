{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba73b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5cb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 加载CSV数据\n",
    "def load_data_from_csv(csv_path):\n",
    "    \"\"\"从CSV文件加载数据\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loaded data from: {csv_path}\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    \n",
    "    # 去除filename列\n",
    "    if 'filename' in df.columns:\n",
    "        df = df.drop('filename', axis=1)\n",
    "    \n",
    "    # 分离特征和标签\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(\"'label' column not found in CSV file\")\n",
    "    \n",
    "    y = df['label'].values\n",
    "    X = df.drop('label', axis=1).values\n",
    "    feature_names = df.drop('label', axis=1).columns.tolist()\n",
    "    \n",
    "    print(f\"Features: {len(feature_names)}\")\n",
    "    print(f\"Positive samples: {np.sum(y == 1)} ({np.sum(y == 1)/len(y)*100:.2f}%)\")\n",
    "    print(f\"Negative samples: {np.sum(y == 0)} ({np.sum(y == 0)/len(y)*100:.2f}%)\")\n",
    "    \n",
    "    return X, y, feature_names\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139a73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载无标签数据\n",
    "def load_unlabeled_data(csv_path, feature_names):\n",
    "    \"\"\"从CSV文件加载无标签数据\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"\\nLoaded unlabeled data from: {csv_path}\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    \n",
    "    # 保存文件名（如果存在）\n",
    "    filenames = df['filename'].values if 'filename' in df.columns else None\n",
    "    \n",
    "    # 去除filename和label列（如果存在）\n",
    "    cols_to_drop = []\n",
    "    if 'filename' in df.columns:\n",
    "        cols_to_drop.append('filename')\n",
    "    if 'label' in df.columns:\n",
    "        cols_to_drop.append('label')\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        df = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    # 确保特征顺序与训练数据一致\n",
    "    if set(df.columns.tolist()) != set(feature_names):\n",
    "        print(\"Warning: Feature names don't match exactly. Reordering columns...\")\n",
    "        df = df[feature_names]\n",
    "    \n",
    "    X = df.values\n",
    "    print(f\"Features: {X.shape[1]}\")\n",
    "    \n",
    "    return X, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7afb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost模型训练函数\n",
    "def train_xgboost_full(X_train, y_train, seed=51):\n",
    "    \"\"\"使用全部数据训练XGBoost模型\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 9,\n",
    "        'learning_rate': 0.042,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'scale_pos_weight': 2.23,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0.2,\n",
    "        'seed': seed\n",
    "    }\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    print(\"\\nTraining XGBoost model on full dataset...\")\n",
    "    model = xgb.train(params, dtrain, num_boost_round=100, verbose_eval=10)\n",
    "    \n",
    "    return model\n",
    "# 模型预测函数\n",
    "def predict_xgboost(model, X_test):\n",
    "    \"\"\"XGBoost预测\"\"\"\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_pred_proba = model.predict(dtest)\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "# 保存模型\n",
    "def save_model(model, model_path, metadata=None):\n",
    "    \"\"\"保存XGBoost模型和元数据\"\"\"\n",
    "    # 创建保存目录\n",
    "    os.makedirs(os.path.dirname(model_path) if os.path.dirname(model_path) else '.', exist_ok=True)\n",
    "    \n",
    "    # 保存模型\n",
    "    model.save_model(model_path)\n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "    \n",
    "    # 保存元数据\n",
    "    if metadata:\n",
    "        metadata_path = model_path.replace('.json', '_metadata.json').replace('.model', '_metadata.json')\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "# 保存预测结果\n",
    "def save_predictions(filenames, y_pred, y_pred_proba, output_path):\n",
    "    \"\"\"保存预测结果到CSV\"\"\"\n",
    "    # 创建DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'filename': filenames if filenames is not None else range(len(y_pred)),\n",
    "        'predicted_label': y_pred,\n",
    "        'probability': y_pred_proba\n",
    "    })\n",
    "    \n",
    "    # 保存到CSV\n",
    "    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nPredictions saved to: {output_path}\")\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f\"Total predictions: {len(results_df)}\")\n",
    "    print(f\"Predicted positive: {np.sum(y_pred == 1)} ({np.sum(y_pred == 1)/len(y_pred)*100:.2f}%)\")\n",
    "    print(f\"Predicted negative: {np.sum(y_pred == 0)} ({np.sum(y_pred == 0)/len(y_pred)*100:.2f}%)\")\n",
    "    print(f\"Probability range: [{y_pred_proba.min():.4f}, {y_pred_proba.max():.4f}]\")\n",
    "    print(f\"Mean probability: {y_pred_proba.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94e004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序\n",
    "def main():\n",
    "    # 设置随机种子\n",
    "    set_seed(42)\n",
    "    \n",
    "    # 配置路径\n",
    "    TRAIN_CSV = 'data/dataset/features_final_38.csv'\n",
    "    UNLABELED_CSV = 'data/dataset/features_38_unlabeled.csv'  # 修改为你的无标签数据路径\n",
    "    MODEL_PATH = 'models/xgboost_full_model.json'\n",
    "    OUTPUT_CSV = 'results/predictions.csv'\n",
    "    \n",
    "    # 1. 加载训练数据\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Step 1: Loading training data\")\n",
    "    print(\"=\" * 60)\n",
    "    X_train, y_train, feature_names = load_data_from_csv(TRAIN_CSV)\n",
    "    \n",
    "    # 2. 训练模型\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step 2: Training model on full dataset\")\n",
    "    print(\"=\" * 60)\n",
    "    model = train_xgboost_full(X_train, y_train, seed=51)\n",
    "    \n",
    "    # 3. 保存模型\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step 3: Saving model\")\n",
    "    print(\"=\" * 60)\n",
    "    metadata = {\n",
    "        'train_samples': len(X_train),\n",
    "        'n_features': len(feature_names),\n",
    "        'feature_names': feature_names,\n",
    "        'positive_samples': int(np.sum(y_train == 1)),\n",
    "        'negative_samples': int(np.sum(y_train == 0)),\n",
    "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_params': {\n",
    "            'max_depth': 9,\n",
    "            'learning_rate': 0.042,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.6,\n",
    "            'scale_pos_weight': 2.23,\n",
    "            'min_child_weight': 1,\n",
    "            'gamma': 0.2,\n",
    "            'num_boost_round': 100\n",
    "        }\n",
    "    }\n",
    "    save_model(model, MODEL_PATH, metadata)\n",
    "    \n",
    "    # 4. 加载无标签数据\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step 4: Loading unlabeled data\")\n",
    "    print(\"=\" * 60)\n",
    "    X_unlabeled, filenames = load_unlabeled_data(UNLABELED_CSV, feature_names)\n",
    "    \n",
    "    # 5. 进行预测\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step 5: Making predictions\")\n",
    "    print(\"=\" * 60)\n",
    "    y_pred, y_pred_proba = predict_xgboost(model, X_unlabeled)\n",
    "    \n",
    "    # 6. 保存预测结果\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step 6: Saving predictions\")\n",
    "    print(\"=\" * 60)\n",
    "    save_predictions(filenames, y_pred, y_pred_proba, OUTPUT_CSV)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Pipeline completed successfully!\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77654880",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
